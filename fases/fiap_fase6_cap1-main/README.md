# FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# fiap_fase6_cap1

## Atividade em Grupo: FIAP - 1TIAOB - 2025/1 - Fase6 Cap 1

## üë®‚Äçüéì Integrantes: 
- <a href="">Alice C. M. Assis - RM 566233</a>
- <a href="">Leonardo S. Souza - RM 563928</a>
- <a href="">Lucas B. Francelino - RM 561409</a> 
- <a href="">Pedro L. T. Silva - RM 561644</a> 
- <a href="">Vitor A. Bezerra - RM 563001</a>

## üë©‚Äçüè´ Professores:
### Tutor(a) 
- <a href="proflucas.moreira@fiap.com.br">Lucas Gomes Moreira</a>
### Coordenador(a)
- <a href="profandre.chiovato@fiap.com.br">Andr√© Godoi Chiovato</a>


## üìú Descri√ß√£o r√°pida do projeto

Neste reposit√≥rio apresentamos a entrega da Fase 6 ‚Äî desenvolvimento e avalia√ß√£o de modelos de Vis√£o Computacional usando YOLO e abordagens concorrentes. O objetivo principal √© montar um dataset customizado com duas classes (A e B), treinar e validar um detector baseado em YOLO, comparar com outras abordagens (YOLO padr√£o e uma CNN treinada do zero) e documentar resultados, conclus√µes e limita√ß√µes.

O projeto tamb√©m oferece duas op√ß√µes opcionais ("Ir Al√©m") para implementa√ß√£o extra: (1) integra√ß√£o com ESP32-CAM para captura e infer√™ncia em tempo real e (2) aplica√ß√µes de Transfer Learning + Fine Tuning com segmenta√ß√£o pr√©via do objeto.

# URL do dataset no Google Drive

- Link para o dataset no Google Drive (pasta principal): <https://drive.google.com/drive/u/1/folders/10XPnZK4l3INy824b0p2vtt5Od0s9g6n8>

## Links dos Notebooks e V√≠deo Demonstrativo

- **Entrega 1**: [yolo_padrao_fiap.ipynb](src/entrega_1/yolo_padrao_fiap.ipynb)
- **Entrega 2**: 
  - [yolo7.ipynb](src/entrega_2/yolo7.ipynb)
  - [CNN.ipynb](src/entrega_2/CNN.ipynb)
- **Ir Al√©m 1**:
  - [yolo_padrao_fiap_esp32cam.ipynb](src/ir_alem_2/criar_dataset_segmentado.ipynb)
- **Ir Al√©m 2**:
  - [criar_dataset_segmentado.ipynb](src/ir_alem_2/criar_dataset_segmentado.ipynb)
  - [cnn_inicial_sem_crop.ipynb](src/ir_alem_2/cnn_inicial_sem_crop.ipynb)
  - [cnn_inicial_com_crop.ipynb](src/ir_alem_2/cnn_inicial_com_crop.ipynb)
  - [fine_tuning.ipynb](src/ir_alem_2/fine_tuning.ipynb)
  - [transfer_learning.ipynb](src/ir_alem_2/transfer_learning.ipynb)
- **V√≠deos Demonstrativos**:
    - [V√≠deo entrega 1](https://www.youtube.com/watch?v=ncGp6qdZ968)
    - [V√≠deo entrega 2](https://youtu.be/CGsucOPqCpY)
    - [V√≠deo Ir Al√©m 1](https://youtu.be/StURW4G3Hww)
    - [V√≠deo Ir Al√©m 2](https://youtu.be/dfWgIeiQotM)

# Entrega 1

## Resumo da implementa√ß√£o 

### [https://www.youtube.com/watch?v=ncGp6qdZ968](https://www.youtube.com/watch?v=ncGp6qdZ968)

[yolo_padrao_fiap.ipynb](src/entrega_1/yolo_padrao_fiap.ipynb)

Neste notebook foi utilizada a linha do tempo abaixo para treinar e avaliar um detector YOLO na base criada em Google Drive.

Fluxo executado:
- Montagem do Google Drive (Colab):
  - from google.colab import drive; drive.mount('/content/drive')
- Defini√ß√£o de caminhos principais:
  - `DATASET_PATH = "/content/drive/MyDrive/FASE6_CAP1/yolo/data.yaml"` (arquivo YAML com paths do dataset e classes)
  - `teste_path = "/content/drive/MyDrive/FASE6_CAP1/yolo/test"` (pasta com imagens de teste)
- Prepara√ß√£o do ambiente:
  - Clone do reposit√≥rio YOLO (quando necess√°rio) e instala√ß√£o de depend√™ncias.
- Modelo usado:
  - `ultralytics` YOLOv8 (pesos iniciais: `yolov8s.pt`).

Hiperpar√¢metros de treino (conforme notebook):
- epochs: 150 (o notebook configurou 150; o treinamento pode apresentar EarlyStopping dependendo do `patience`)
- imgsz: 640
- batch: 16
- patience: 30
- workers: 8
- device: 0
- seed: 42

Comando de treino (exemplo usado no notebook):
- model.train(data=DATASET_PATH, epochs=150, imgsz=640, batch=16, patience=30, workers=8, device=0, seed=42)

Infer√™ncia / gera√ß√£o de resultados:
- Previs√µes:
  - Ajustes: conf=0.65, iou=0.5, max_det=50
  - Salvamento: `save=True`, `save_txt=True`, `save_conf=True`
  - Projeto / pasta de sa√≠da (exemplo):
    - project: `/content/drive/MyDrive/FASE6_CAP1/yolo/outputs`
    - name: `banana_maca` (nome da execu√ß√£o)
- Resultado final informado no notebook: "Arquivos salvos em: /content/drive/MyDrive/FASE6_CAP1/yolo/outputs/banana_maca"

## Avalia√ß√£o (s√≠ntese retirada do pr√≥prio notebook)
- Facilidade de uso / integra√ß√£o: fluxo simples usando a API `ultralytics` (YOLOv5) ‚Äî r√°pida integra√ß√£o no Colab com Drive.
- Precis√£o: o notebook relata boa detec√ß√£o para a classe `maca` com recall satisfat√≥rio em execu√ß√µes iniciais.
- Tempo de treinamento: o autor notou que o modelo encerrou via EarlyStopping por volta de ~35 √©pocas em uma execu√ß√£o, embora o treino estivesse configurado para at√© 150 √©pocas.
- Tempo de infer√™ncia: aproximadamente 41,8 ms por imagem (valor reportado no notebook como exemplo de medi√ß√£o).

## Como reproduzir (passo a passo m√≠nimo no Colab)
1. Abrir o notebook `src/entrega_1/yolo_padrao_fiap.ipynb` no Colab (ou copiar o conte√∫do para um novo notebook no Drive).
2. Montar o Drive: `from google.colab import drive; drive.mount('/content/drive')`.
3. Verificar que `DATASET_PATH` e `teste_path` apontam para sua pasta no Drive (ex.: `/content/drive/MyDrive/FASE6_CAP1/yolo/`).
4. Instalar/rodar YOLO (se for usar o reposit√≥rio local): `!git clone https://github.com/ultralytics/yolov5` e instalar requisitos; ou usar a API `ultralytics` (j√° presente no notebook).
5. Executar c√©lulas de treino com os hiperpar√¢metros desejados (sugest√£o: testar 30 e 60 √©pocas como comparativo exigido no enunciado).
6. Rodar a c√©lula de infer√™ncia e verificar os resultados salvos em `.../yolo/outputs/<nome_execucao>`.

## Arquivos gerados e local de salvamento
- Checkpoints e pesos: quando salvos pelo YOLO, ficam no diret√≥rio padr√£o do framework (ou no Drive, dependendo da configura√ß√£o).
- Imagens de teste com detec√ß√µes: `/content/drive/MyDrive/FASE6_CAP1/yolo/outputs/<nome_execucao>`
- Arquivos de texto com predi√ß√µes: salvos junto √†s imagens se `save_txt=True`.

## Observa√ß√µes e recomenda√ß√µes
- Ajuste `DATASET_PATH` no YAML para garantir que os paths de `train`, `val` e `test` estejam corretos antes de treinar.
- Se quiser reproduzir localmente, adapte os caminhos para o seu sistema e verifique compatibilidade de GPU (device index).
- Recomenda-se executar pelo menos duas sess√µes de treino com √©pocas bem diferentes (ex.: 30 e 60) para comparar m√©tricas conforme requisito da Entrega 1.

# Entrega 2

## Resumo da implementa√ß√£o 

### [https://youtu.be/CGsucOPqCpY](https://youtu.be/CGsucOPqCpY)

[yolo7.ipynb](src/entrega_2/yolo7.ipynb)

Neste notebook foi utilizada a linha do tempo abaixo para treinar e avaliar um detector YOLOv7 na base criada em Google Drive.

Fluxo executado:
- Montagem do Google Drive (Colab):
  - from google.colab import drive; drive.mount('/content/drive')
- Defini√ß√£o de caminhos principais:
  - `DATASET_PATH = "/content/drive/MyDrive/FASE6_CAP1/yolo/data.yaml"` (arquivo YAML com paths do dataset e classes)
  - `teste_path = "/content/drive/MyDrive/FASE6_CAP1/yolo/test"` (pasta com imagens de teste)
- Prepara√ß√£o do ambiente:
  - Clone do reposit√≥rio YOLOv7 e instala√ß√£o de depend√™ncias.
- Modelo usado:
  - YOLOv7 (pesos iniciais: `yolov7.pt`).

Hiperpar√¢metros de treino (conforme notebook):
- epochs: 150
- batch-size: 16
- img: 640
- device: 0

Comando de treino (exemplo usado no notebook):
- python train.py --weights yolov7.pt --data $DATASET_PATH --epochs 150 --batch-size 16 --img 640 --device 0

Infer√™ncia / gera√ß√£o de resultados:
- Previs√µes:
  - Ap√≥s treinamento, usar detect.py para infer√™ncia.
  - Exemplo: python detect.py --weights runs/train/exp/weights/best.pt --source $teste_path --img 640
- Resultado final informado no notebook: Similar ao YOLO padr√£o, com arquivos salvos em diret√≥rio de sa√≠da.

## Avalia√ß√£o (s√≠ntese retirada do pr√≥prio notebook)
- Facilidade de uso / integra√ß√£o: O uso foi bastante simples e direto, com pipeline de treinamento e infer√™ncia pronto, dispensando defini√ß√£o manual de camadas ou arquitetura.
- Precis√£o: O modelo apresentou evolu√ß√£o r√°pida nas primeiras √©pocas, atingindo melhor desempenho na √©poca 5, com poss√≠vel instabilidade em √©pocas posteriores devido √† falta de early stopping.
- Tempo de treinamento: O treinamento completo levou 35 √©pocas (~0,053 horas) at√© EarlyStopping.
- Tempo de infer√™ncia: A infer√™ncia foi r√°pida, com detec√ß√£o em aproximadamente 41,8 ms por imagem.

## Como reproduzir (passo a passo m√≠nimo no Colab)
1. Abrir o notebook `src/entrega_2/yolo7.ipynb` no Colab (ou copiar o conte√∫do para um novo notebook no Drive).
2. Montar o Drive: `from google.colab import drive; drive.mount('/content/drive')`.
3. Verificar que `DATASET_PATH` e `teste_path` apontam para sua pasta no Drive (ex.: `/content/drive/MyDrive/FASE6_CAP1/yolo/`).
4. Clonar e instalar YOLOv7: `!git clone https://github.com/WongKinYiu/yolov7` e `!pip install -r requirements.txt`.
5. Executar treinamento: `!python train.py --weights yolov7.pt --data $DATASET_PATH --epochs 150 --batch-size 16 --img 640 --device 0`.
6. Para infer√™ncia: `!python detect.py --weights runs/train/exp/weights/best.pt --source $teste_path --img 640` e verificar resultados.

## Arquivos gerados e local de salvamento
- Checkpoints e pesos: Salvos em runs/train/exp/weights/.
- Imagens de teste com detec√ß√µes: Salvas em runs/detect/exp/.
- Arquivos de texto com predi√ß√µes: Gerados junto √†s imagens.

## Observa√ß√µes e recomenda√ß√µes
- Ajuste `DATASET_PATH` no YAML para garantir que os paths estejam corretos.
- Para reproduzir localmente, adapte caminhos e verifique GPU.
- Recomenda-se testar com diferentes √©pocas (ex.: 30 e 60) para compara√ß√£o, conforme enunciado.

## CNN Treinada do Zero

[CNN.ipynb](src/entrega_2/CNN.ipynb)

Neste notebook foi implementada uma Rede Neural Convolucional (CNN) treinada do zero para classifica√ß√£o de imagens, utilizando TensorFlow/Keras, na base criada em Google Drive.

Fluxo executado:
- Montagem do Google Drive (Colab):
  - from google.colab import drive; drive.mount('/content/drive')
- Defini√ß√£o de caminhos principais:
  - `base_dir = "/content/drive/MyDrive/Cap6_Fase1"`
  - `train_dir` e `test_dir` para pastas de treino e teste.
- Prepara√ß√£o do ambiente:
  - Importa√ß√£o de bibliotecas: TensorFlow, Keras, etc.
- Modelo usado:
  - CNN customizada com camadas Conv2D, MaxPooling, Flatten, Dense e Dropout.

Hiperpar√¢metros de treino (conforme notebook):
- epochs: 30 (com EarlyStopping, patience=5)
- batch_size: 16
- img_height, img_width: 128, 128
- Data augmentation: rotation_range=30, width_shift_range=0.1, etc.

Arquitetura da CNN:
- Conv2D(32, (3,3), relu) -> MaxPooling2D((2,2))
- Conv2D(64, (3,3), relu) -> MaxPooling2D((2,2))
- Conv2D(128, (3,3), relu) -> MaxPooling2D((2,2))
- Flatten -> Dense(128, relu) -> Dropout(0.5) -> Dense(num_classes, softmax)

Infer√™ncia / gera√ß√£o de resultados:
- Avalia√ß√£o no conjunto de teste ap√≥s treinamento.
- Visualiza√ß√µes: gr√°ficos de acur√°cia/loss, histograma de predi√ß√µes.

## Avalia√ß√£o (s√≠ntese retirada do pr√≥prio notebook)
- Facilidade de uso / integra√ß√£o: Simples e direto, com controle total sobre as camadas e ajustes, ideal para aprendizado.
- Precis√£o: Acur√°cia de valida√ß√£o m√°xima de 98,75% e final no teste de 87,50%. Boa generaliza√ß√£o, mas com leve tend√™ncia a overfitting.
- Tempo de treinamento: Cada √©poca levou 12-16 segundos, treinamento r√°pido.
- Tempo de infer√™ncia: Extremamente r√°pido, adequado para aplica√ß√µes em tempo real.

## Como reproduzir (passo a passo m√≠nimo no Colab)
1. Abrir o notebook `src/entrega_2/CNN.ipynb` no Colab.
2. Montar o Drive: `from google.colab import drive; drive.mount('/content/drive')`.
3. Verificar caminhos: `base_dir`, `train_dir`, `test_dir`.
4. Executar c√©lulas de importa√ß√£o e defini√ß√£o de geradores de imagens.
5. Definir e compilar o modelo CNN.
6. Treinar com `model.fit()`, usando EarlyStopping.
7. Avaliar e visualizar m√©tricas.

## Arquivos gerados e local de salvamento
- Modelo treinado: Salvo implicitamente no Colab, pode ser exportado com `model.save()`.
- Gr√°ficos e visualiza√ß√µes: Gerados no notebook.

## Observa√ß√µes e recomenda√ß√µes
- Adequado para datasets pequenos, mas pode sofrer overfitting sem augmentation suficiente.
- Comparar com YOLO para ver diferen√ßas em detec√ß√£o vs. classifica√ß√£o.

# Ir Al√©m 1 

## Resumo da implementa√ß√£o

### [https://youtu.be/StURW4G3Hww](https://youtu.be/StURW4G3Hww)

[yolo_padrao_fiap.ipynb](src/ir_alem_1/yolo_padrao_fiap_esp32cam.ipynb)

Neste notebook foi desenvolvido um Sistema de Reconhecimento com ESP32-CAM e YOLO, foi utilizado o modelo da Entrega 1 para integrar com o ESP32-WROVER-DEV (CAM).

Fluxo executado:
- Montagem do Google Drive (Colab):
  - from google.colab import drive; drive.mount('/content/drive')
- Defini√ß√£o de caminhos principais:
  - `DATASET_PATH = "/content/drive/MyDrive/FASE6_CAP1/yolo/data.yaml"` (arquivo YAML com paths do dataset e classes)
  - `teste_path = "/content/drive/MyDrive/FASE6_CAP1/yolo/test"` (pasta com imagens de teste)
- Prepara√ß√£o do ambiente:
  - Clone do reposit√≥rio YOLO (quando necess√°rio) e instala√ß√£o de depend√™ncias.
- Modelo usado:
  - `ultralytics` YOLOv8 (pesos iniciais: `yolov8s.pt`).
- Codigo do ESP32 para conex√£o via WIFI
- Chamada da fun√ß√£o Screem por IP para executar o c√≥digo em tempo real

## Objetivo
Implementar um sistema de vis√£o computacional em tempo real utilizando um m√≥dulo **ESP32-CAM f√≠sico**, capaz de reconhecer **bananas e ma√ß√£s** com o modelo YOLO treinado na Entrega 1.

## Funcionamento
O ESP32-CAM transmite imagens via Wi-Fi para o Python, que processa o stream usando o modelo `best.pt` e realiza a detec√ß√£o dos objetos em tempo real.

## Tecnologias Utilizadas
- YOLOv5 (Ultralytics)
- Python + OpenCV
- ESP32-CAM (Arduino IDE)
- Google Colab / Jupyter

## Demonstra√ß√£o
[Assista ao v√≠deo no YouTube (n√£o listado)](link_do_video_aqui)


# Ir Al√©m 2

## Criar Dataset Segmentado

### [https://youtu.be/dfWgIeiQotM](https://youtu.be/dfWgIeiQotM)

[criar_dataset_segmentado.ipynb](src/ir_alem_2/criar_dataset_segmentado.ipynb)

Neste notebook √© baixado um dataset de imagens de animes e realizada a segmenta√ß√£o das imagens para criar crops focados nos objetos principais, preparando o dataset para treinamento de CNNs.

Fluxo executado:
- Download do dataset via KaggleHub.
- Sele√ß√£o de classes espec√≠ficas (ex.: Dragon Ball Z, Samurai X).
- Aplica√ß√£o de segmenta√ß√£o para extrair regi√µes de interesse (crops).
- Salvamento do dataset segmentado em pasta local.

Arquitetura/Abordagem:
- Utiliza t√©cnicas de segmenta√ß√£o para focar em objetos centrais das imagens.

Avalia√ß√£o:
- Facilidade: Automatizado, mas requer ajustes manuais para segmenta√ß√£o precisa.
- Resultado: Dataset preparado com imagens cropped, melhorando a performance de modelos subsequentes.

## CNN Inicial sem Crop

[cnn_inicial_sem_crop.ipynb](src/ir_alem_2/cnn_inicial_sem_crop.ipynb)

Neste notebook √© treinada uma CNN do zero sem segmenta√ß√£o pr√©via, utilizando um dataset baixado do Kaggle.

Fluxo executado:
- Download e prepara√ß√£o do dataset (ex.: anime images).
- Defini√ß√£o de geradores de imagens com redimensionamento.
- Constru√ß√£o e treinamento de uma CNN simples (Conv2D, MaxPooling, Dense).
- Avalia√ß√£o com matriz de confus√£o.

Arquitetura:
- Conv2D(32, 3, relu) -> MaxPooling2D -> Conv2D(64, 3, relu) -> MaxPooling2D -> Flatten -> Dense(128, relu) -> Dropout(0.3) -> Dense(num_classes, softmax)

Hiperpar√¢metros:
- epochs: 50 (com EarlyStopping, patience=5)
- batch_size: 32
- img_size: (200, 200)

Avalia√ß√£o:
- Precis√£o: Acur√°cia final inferior comparada a vers√µes com crop, devido √† complexidade das imagens n√£o segmentadas.
- Tempo: Treinamento r√°pido, mas menor performance.

## CNN Inicial com Crop

[cnn_inicial_com_crop.ipynb](src/ir_alem_2/cnn_inicial_com_crop.ipynb)

Neste notebook √© treinada uma CNN do zero utilizando o dataset segmentado (com crops) criado anteriormente.

Fluxo executado:
- Carregamento do dataset segmentado.
- Constru√ß√£o e treinamento de CNN similar √† vers√£o sem crop.
- Avalia√ß√£o com matriz de confus√£o.

Arquitetura: Id√™ntica √† CNN sem crop.

Hiperpar√¢metros: Id√™nticos.

Avalia√ß√£o:
- Precis√£o: Acur√°cia impressionante de 0.96, demonstrando o benef√≠cio da segmenta√ß√£o pr√©via.
- Tempo: Treinamento eficiente, com EarlyStopping.

## Transfer Learning

[transfer_learning.ipynb](src/ir_alem_2/transfer_learning.ipynb)

Neste notebook √© aplicado Transfer Learning utilizando ResNet50 pr√©-treinada no ImageNet, com o dataset segmentado.

Fluxo executado:
- Carregamento do ResNet50 (pesos ImageNet, sem top layers).
- Congelamento das camadas base.
- Adi√ß√£o de camadas densas para classifica√ß√£o.
- Treinamento apenas das camadas superiores.

Arquitetura:
- ResNet50 (base congelada) -> GlobalAveragePooling2D -> Dense(128, relu) -> Dropout(0.3) -> Dense(num_classes, softmax)

Hiperpar√¢metros:
- epochs: 50 (EarlyStopping)
- batch_size: 32

Avalia√ß√£o:
- Precis√£o: Acur√°cia de 0.96, superior a CNNs treinadas do zero devido ao aproveitamento de features pr√©-treinadas.
- Tempo: Treinamento mais r√°pido e eficiente.

## Fine Tuning

[fine_tuning.ipynb](src/ir_alem_2/fine_tuning.ipynb)

Neste notebook √© realizado Transfer Learning seguido de Fine Tuning, ajustando algumas camadas da ResNet50 para o dataset espec√≠fico.

Fluxo executado:
- Transfer Learning inicial (como acima).
- Descongelamento de camadas superiores da ResNet50.
- Treinamento com learning rate menor para fine tuning.

Arquitetura: Similar ao Transfer Learning, mas com ajuste fino das camadas base.

Avalia√ß√£o:
- Precis√£o: Melhor performance potencial comparada ao Transfer Learning puro, adaptando melhor ao dataset.
- Tempo: Mais demorado devido ao ajuste de mais par√¢metros.

## üìÅ Estrutura do reposit√≥rio

- README.md               -> documenta√ß√£o principal do projeto
- assets/                 -> logos e imagens de suporte
  - logo-fiap.png
- src/                    -> notebooks e scripts
  - entrega_1/            -> notebooks para Entrega 1
    - yolo_padrao_fiap.ipynb
  - entrega_2/            -> notebooks para Entrega 2
    - CNN.ipynb
    - yolo7.ipynb
  - ir_alem_2/            -> notebooks para Ir Al√©m 2
    - cnn_inicial_com_crop.ipynb
    - cnn_inicial_sem_crop.ipynb
    - criar_dataset_segmentado.ipynb
    - fine_tuning.ipynb
    - transfer_learning.ipynb

## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> est√° licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>
